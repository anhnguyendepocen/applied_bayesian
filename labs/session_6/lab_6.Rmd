---
title: "Lab Session 6"
output: 
# pdf_document
  semantic.doc::semantic_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = F)
```

<br>
<br>
<div class = "ui text container">

<h1 class = "ui header">
 Lab Session 6
</h1>


* Gelman Rubin Stats = Ration from within and between variance of MCMC Chains.  
* $Naive SE = \frac{SD}{\sqrt{n}}$
* Time-serieis SE (+ penalty)

$$Y \sim f(y|\theta, \alpha)$$

$$\theta = g(X, \beta)$$

* probability function = binomial for binary data
* link function = logit

$$logit(p) = \beta_0 + \beta_1 x$$

* Phi function translates between PDF to CDP and the logit the other way around. 

## Packages 

```{r}
pacman::p_load(rjags, dplyr, purrr, tidyr, ggplot2, broom, rjags)
ggplot2::theme_set(theme_bw())
# tinytex::install_tinytex()
devtools::session_info()
set.seed(2018)
```


## Data

```{r}
dat <- get(load("../data/Bayes_Student_Survey.RData")) %>% 
  mutate(friend_log = log(friend + 1))

glimpse(dat)
```


A reduced dataset of Student Panel Survey during the Lecture in Introduction to Political Methodology Winter term 2016/2017 at the University of Konstanz 

* `poleff` Political Efficacy (Likert Score based on 7 items) A larger value = higher level of efficacy
* `friend` Number of alteri in friendship network
* `poldisc` Number of alteri in political discussion network
* `lr.self` Ideological orientation (left right self-placement) 1: Left <- -> 11: Right
* `lr.self.2` Ideological orientation (left right self-placement, second measurement) 1: Left <- -> 11: Right
* `univ.election` Vote intention at the next university election. 1: Yes; 0: other (No and DK)
* `polint` interest at university politics 1: not interested at all <- -> 5 strongly interested
* `tuition` opinion on the general tuition fee for German universities 1: support; 2: reject; 3: indifferent
* `acceptable` acceptable level of the tuition fee (in Euro per Semester) (Only those who support the tuition fee or indifferent)
* protest1 - protest6 willingness to participate a protest action against the general tuition fee 1: yes; 0: no
    + `protest1` demonstration in Konstanz 
    + `protest2` demonstration in Stuttgart 
    + `protest3` giving signature at petitions 
    + `protest4` strike 
    + `protest5` occupation of university buildings 
    + `protest6` legal dispute at courts

# Models

## Binary Logit Model

### JAGS Modell

```{r}
logit.model <- "model{
  for (i in 1:N){
    y[i] ~ dbern(p[i])
    logit(p[i]) <- ystar[i]
    ystar[i] <- alpha + beta * x[i]
  }

  alpha ~ dnorm(0, 0.0001)
  beta ~ dnorm(0, 0.0001)

}"

write(logit.model, "Bayes_Binary_Logit_Student_Survey.bug")
```


```{r}
jags.data <- list(
  y = dat$univ.election,
  x = dat$poleff,
  N = nrow(dat)
)

jags.logit <- jags.model(
  file = "Bayes_Binary_Logit_Student_Survey.bug",
  data = jags.data, 
  n.chains = 3
)

jags.logit.out <- coda.samples(
  jags.logit,
  variable.names = c("alpha", "beta"),
  n.iter = 20000, 
  thin = 50
)
```


### Checking convergence 

and chain auto-correlation

Subsample 
 
```{r}
gelman.plot(jags.logit.out)
autocorr.plot(jags.logit.out)

summary(jags.logit.out)
plot(jags.logit.out)
```

for comparison with ML results

```{r}
ml.logit.out <- glm(univ.election ~ poleff, family=binomial(link="logit"), data=dat)
summary(ml.logit.out)
```

### Predictions

Making a prediction with interval for different x values 

```{r}
# extract coefficients and build a matrix
alpha.vec <- unlist(jags.logit.out[,"alpha"])
beta.vec <- unlist(jags.logit.out[,"beta"])
coef.mat <- cbind(alpha.vec,beta.vec)

# Set up a matrix for x 
range(dat$poleff) # check the range
x.var <- seq(min(dat$poleff),max(dat$poleff),by=0.1)
x.mat <- cbind(1,x.var)

# Prediction
predict.mat <- coef.mat%*% t(x.mat)
predict.mat <- exp(predict.mat)/(1+exp(predict.mat))

# Calculating the percentiles and mean of predictions
predict.ci <- apply(predict.mat,2,quantile,pr=c(0.025,0.5,0.975))
predict.mean <- apply(predict.mat,2,mean)

# Plot everything
plot(x.var,predict.ci[1,],type="l",ylim=c(0,1))
par(new=T)
plot(x.var,predict.ci[2,],type="l",ylim=c(0,1))
par(new=T)
plot(x.var,predict.ci[3,],type="l",ylim=c(0,1))
par(new=T)
plot(x.var,predict.mean,type="l",ylim=c(0,1),col="red")
```



## Regression for Count Variables

```{r}
hist(dat$poldisc)
hist(dat$lr.self)

plot(dat$poldisc ~ dat$lr.self)
pois.out <- glm(poldisc ~ lr.self, family=poisson,data=dat)
summary(pois.out)
```

### JAGS Model

```{r}
pois.model <- "model{
   for (i in 1:N){
       y[i] ~ dpois(lambda[i])
       log(lambda[i]) <- inprod(X[i,],beta[])
   }

  for (j in 1:J){
    beta[j] ~ dnorm(0,0.001)
  }
}"

write(pois.model, "Bayes_Poisson_Student_Survey.bug")

jags.data <- list(
  y = dat$poldisc,
  N = nrow(dat),
  X = cbind(1, dat$lr.self),
  J = 2 #dim(X)[2]
)

# y <- dat$poldisc
# X <- cbind(1,dat$lr.self)
# 
# N <- length(y)
# J <- dim(X)[2]
# 
# jags.data <- list(y=y,N=N,J=J,X=X)

jags.pois <- jags.model(
  file = "Bayes_Poisson_Student_Survey.bug",
  data = jags.data, 
  n.chains = 3
)
```


### Delete missings

```{r}
pois.model <- "model{
   for (i in 1:N){
       y[i] ~ dpois(lambda[i])
       log(lambda[i]) <- inprod(X[i,],beta[])
   }

  for (j in 1:J){
    beta[j] ~ dnorm(0,0.001)
  }
}"

write(pois.model, "Bayes_Poisson_Student_Survey.bug")

dat_clean <- dat %>% 
  drop_na(lr.self, poldisc) %>% 
  select(lr.self, poldisc) %>% 
  cbind(1, .)

jags.data <- list(
  y = dat_clean$y,
  N = nrow(dat_clean),
  X = dat_clean[, -length(dat_clean)],
  J = length(dat_clean) - 1 #dim(X)[2]
)

jags.pois <- jags.model(
  file = "Bayes_Poisson_Student_Survey.bug",
  data = jags.data, 
  n.chains = 3
)

update(jags.pois, 2000)

jags.pois.out <- coda.samples(
  jags.pois,
  variable.names = c("beta"),
  n.iter = 5000, 
  thin = 1
)
```

```{r}
plot(jags.pois.out)
gelman.plot(jags.pois.out)
summary(jags.pois.out)
```


### Impute Missings

```{r}
pois.model <- "model{
   for (i in 1:N){
       y[i] ~ dpois(lambda[i])
       log(lambda[i]) <- inprod(X[i,], beta[])
       X[i,2] ~ dunif(1, 11)   # Impute by using a uniform distribution
   }

  for (j in 1:J){
    beta[j] ~ dnorm(0,0.001)
  }
}"

write(pois.model, "Bayes_Poisson_Student_Survey.bug")

y <- dat$poldisc
X <- cbind(1,dat$lr.self)
N <- length(y)
J <- dim(X)[2]

jags.data <- list(y=y,N=N,J=J,X=X)

jags.pois <- jags.model(
  file = "Bayes_Poisson_Student_Survey.bug",
  datam = jags.data, 
  n.chains = 3
)

update(jags.pois, 2000)

jags.pois.out <- coda.samples(
  jags.pois,
  variable.names = c("beta"),
  n.iter = 20000, 
  thin = 20
)
```


```{r}
plot(jags.pois.out)
gelman.plot(jags.pois.out)
summary(jags.pois.out)
```

For comparison: A single impuration with the mid value

```{r}
summary(glm(poldisc ~ lr.self, family=poisson,data=dat))

lr.self.imp <- ifelse(is.na(dat$lr.self),6,dat$lr.self)
cbind(lr.self.imp,dat$lr.self)     # check!
summary(glm(poldisc ~ lr.self.imp, family=poisson,data=dat))
```

Plotting the predicted size of network

```{r}
beta <- as.matrix(jags.pois.out)

# Prediction by using quantiles
x.scale <- range(dat$lr.self,na.rm=T)
x.scale <- seq(x.scale[1],x.scale[2],length.out=100)
X0 <- cbind(1,x.scale)
predicted <- beta %*% t(X0)
predicted <- exp(predicted)
predicted <- apply(predicted,2,quantile,c(.05,.5,.95))
```

```{r}
for (i in 1:2){
plot(dat$lr.self,jitter(dat$poldis),xlab="Left Right Ideology",
                                                ylab="Size of pol.disc.network")
if (i==2){
   lines(x.scale,predicted[2,],col="red")
   lines(x.scale,predicted[1,],col="red",lty=2)
   lines(x.scale,predicted[3,],col="red",lty=2)
   }
}
#dev.off()
```


## Negative binomial regression

```{r}
nb.out <- glm.nb(poldisc ~ lr.self,data=dat)
summary(nb.out)

# for comparison
pois.out <- glm(poldisc ~ lr.self, family=poisson,data=dat)
summary(pois.out)
```


### RJAGS

```{r}

nb.model <- "model{
   for (i in 1:N){
       y[i] ~ dpois(lambda2[i])
       lambda2[i] <- lambda[i]* rho[i]
       rho[i] ~ dgamma(r,r)
       log(lambda[i]) <- inprod(X[i,],beta[])
       X[i,2] ~ dunif(1,11)   # Impute by using a uniform distribution
   }

  for (j in 1:J){
    beta[j] ~ dnorm(0,0.001)
  }

 r ~ dgamma(0.0001,0.0001)
}"

write(nb.model,
      "Bayes_NB_Student_Survey_JAGS.bug")

y <- dat$poldis
N <- length(y)
X <- cbind(1,dat$lr.self)
J <- dim(X)[2]
jags.data <- list(y=y,N=N,J=J,X=X)
jags.nb <- jags.model(file=
                        "Bayes_NB_Student_Survey_JAGS.bug",
                      data=jags.data, n.chains=3)

parameters <- c("beta","r")

update(jags.nb, 2000)

jags.nb.out <- coda.samples(jags.nb,
                            variable.names=parameters,
                            n.iter=20000, thin=10)
plot(jags.nb.out)
gelman.plot(jags.nb.out)

summary(jags.nb.out)
```

### Another

```{r}

nb2.model <- "model{
 for (i in 1:N) {
    y[i] ~ dnegbin(p[i],r)
    p[i] <- r/(r+lambda[i])
    log(lambda[i]) <- inprod(X[i,],beta[])
    X[i,2] ~ dunif(1,11)   # Impute by using a uniform distribution
 }

 for (j in 1:J){
    beta[j] ~ dnorm(0,0.001)
 }

 r ~ dgamma(0.001,0.001)
}"

write(nb2.model,"Bayes_NB2_Student_Survey_JAGS.bug")

jags.nb2 <- jags.model(file=
                        "Bayes_NB2_Student_Survey_JAGS.bug",
                      data=jags.data, n.chains=3)

parameters <- c("beta","r")

update(jags.nb2, 2000)

jags.nb2.out <- coda.samples(jags.nb2,
                            variable.names=parameters,
                            n.iter=2000, thin=1)
summary(jags.nb2.out)

# to compare
summary(jags.nb.out)
```


# Deviance and DIC  

Task: Calculate Deviance Information Criterion of the following Poisson Model


```{r}

# Calculate LL in JAGS
pois.model.loglike <- "model{
   for (i in 1:N){
       y[i] ~ dpois(lambda[i])
       log(lambda[i]) <- inprod(X[i,],beta[])
       # Log-Likelihood of individual response
       loglike[i] <- y[i]*log(lambda[i]) - lambda[i] - logfact(y[i])
   }

  for (j in 1:J){
    beta[j] ~ dnorm(0,0.001)
  }
  
  LL <- sum(loglike[]) 
}"

write(pois.model.loglike,
      "Bayes_Poisson_loglike_Student_Survey.bug")

y <- dat$poldisc
X <- cbind(1,dat$lr.self)
X <- na.omit(X)                   # Omit missings in X
y <- y[-attributes(X)$na.action]  # Omit the correspnding obs in y

N <- length(y)
J <- dim(X)[2]

jags.data <- list(y=y,N=N,J=J,X=X)
jags.pois <- jags.model(file=
                        "Bayes_Poisson_loglike_Student_Survey.bug",
                      data=jags.data, n.chains=3)

update(jags.pois, 2000)

jags.pois.out <- coda.samples(jags.pois,
                            variable.names=c("beta","LL"),
                            n.iter=5000, thin=1)


LL <- unlist(jags.pois.out[,"LL"])

beta.posterior <- as.matrix(jags.pois.out[,c("beta[1]","beta[2]")])

dev.LL <- LL * -2

dev.bar <- mean(dev.LL)

# calculating deviance hat
mean.posterior <- apply(beta.posterior,2,mean)
lambda.hat <- X %*% mean.posterior
lambda.hat <- exp(lambda.hat)
loglike.hat <- y*log(lambda.hat) - lambda.hat - lfactorial(y)
dev.hat <- sum(loglike.hat * -2)


pD <- dev.bar - dev.hat
dev.bar
pD
dev.bar + pD



# ------------------------------------------------------------------------------
#    Calculatng deviance II (using dpois())
#
beta.posterior <- as.matrix(jags.pois.out[,c("beta[1]","beta[2]")])

# Calculating deviance bar
lambda <- X %*% t(beta.posterior)
lambda <- exp(lambda)
loglike <- lambda
for (i in 1:ncol(lambda)){
     loglike[,i] <- dpois(y,lambda=lambda[,i],log=TRUE)
}
dev.LL2 <- loglike * -2
dev.LL2 <- apply(dev.LL2,2,sum,na.rm=T)

plot(dev.LL,dev.LL2)  # check with deviance

dev.bar <- mean(dev.LL2)

# calculating deviance hat
mean.posterior <- apply(beta.posterior,2,mean)
lambda.hat <- X %*% mean.posterior
lambda.hat <- exp(lambda.hat)
loglike.hat <- dpois(y,lambda=lambda.hat,log=TRUE)
dev.hat <- sum(loglike.hat * -2)


pD <- dev.bar - dev.hat
dev.bar
pD
dev.bar + pD


# ------------------------------------------------------------------------------
#    Calculatng deviance III  (using dic-module)
#
load.module('dic')

jags.pois.out <- coda.samples(jags.pois,
                            variable.names=c("beta","LL","deviance"),
                            n.iter=5000, thin=1)

# Likelihood (y|beta) and deviance
posterior.dev <- unlist(jags.pois.out[,"deviance"])
beta.posterior <- as.matrix(jags.pois.out[,c("beta[1]","beta[2]")])

dev.bar <- mean(posterior.dev)

# calculating deviance hat
mean.posterior <- apply(beta.posterior,2,mean)
lambda.hat <- X %*% mean.posterior
lambda.hat <- exp(lambda.hat)
loglike.hat <- dpois(y,lambda=lambda.hat,log=TRUE)
dev.hat <- sum(loglike.hat * -2)


pD <- dev.bar - dev.hat
dev.bar
pD
dev.bar + pD


# ------------------------------------------------------------------------------
#    Calculatng deviance IV   (using dic.samples())
#
pois.dic.out <- dic.samples(jags.pois,n.iter=2000, thin=1)
pois.dic.out
```



</div>